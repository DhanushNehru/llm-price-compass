"backend","benchmark_duration","best_of","completed","cost_per_hour","date","duration","gpu","input_throughput","issue","mean_e2e_latency","mean_itl","mean_tpot","mean_ttft","median_e2e_latency","median_itl","median_tpot","median_ttft","model_id","num_prompts","output_throughput","p99_itl","p99_tpot","p99_ttft","provider","request_rate","request_throughput","successful_requests","tokenizer_id","total_generated_tokens","total_generated_tokens_ret","total_input_tokens","total_output_tokens","traffic_request_rate","use_beam_search"
"sglang",35.45,,,3.02,"20240814-155812",,"NVIDIA H100",6070.48,,14328.17,71.79,145.31,773.1,13759.53,49.35,81.55,193.72,"meta-llama/Meta-Llama-3.1-8B-Instruct",,5595.07,291.88,915.34,4118.65,"scaleway",,28.21,1000,"meta-llama/Meta-Llama-3.1-8B-Instruct",198343,197967,215196,,200,
"vllm",,,1000,2.84,"20240820-143000",97.65,"NVIDIA A10G",2203.64,"https://github.com/arc53/llm-price-compass/issues/6",,,,,,,,,"meta-llama/Meta-Llama-3.1-8B-Instruct",1000,441.76,,,,"aws",,10.24,,"meta-llama/Meta-Llama-3.1-8B-Instruct",,,215196,43140,,
"vllm",,1,1000,0.84,"20240813-143958",385.30312793600024,"NVIDIA L4",558.5109084184351,,,,,,,,,,"meta-llama/Meta-Llama-3.1-8B-Instruct",1000,513.2037236740132,,,,"scaleway","inf",2.5953591536015312,,"meta-llama/Meta-Llama-3.1-8B-Instruct",,,215196,197739,,false
